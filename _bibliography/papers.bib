---
---

@string{aps = {American Physical Society,}}

# 2023
@article{yang2023attention,
  abbr={Preprint},
  title={Shared and distinct neural signatures of feature and spatial attention},
  author={Yang, Anmin and Tian, Jinhua and Wang, Wenbo and Liu, Jia and Zhou, Linqin and Zhou, Ke},
  journal={bioRxiv},
  volume={},
  number={},
  pages={},
  year={2023},
  publisher={bioRxiv},
  abstract={The debate regarding whether feature attention (FA) and spatial attention (SA) share a common neural mechanism continues to persist. Previous studies have identified frontoparietal regions consistently activated during different visual attention tasks. However, these studies had limited sample sizes and methodological constraints inherent in univariate analysis. To address these limitations, the current study employed a machine-learning-based multivariate analysis approach, leveraging a large sample size of 235 participants. This enabled a comprehensive investigation into the shared and distinct neural signatures associated with FA and SA. Our findings revealed that both neural signatures exhibited the ability to predict each other, although inter-task prediction performance was notably weaker compared to intra-task prediction. The findings lends support to the presence of both shared and distinct neural mechanisms underlying FA and SA. Notably, the frontoparietal network emerged as the most predictive network for FA, while the visual network played a primary role in SA. Moreover, we observed overlapping areas between the two attention tasks. Specifically, through cluster-level analysis with single-cluster prediction, we identified four regions located at the temporal/occipital lobes (i.e., the left Lingual Gyrus (LG), right Occipital Pole (OcP), right Occipital Fusiform Gyrus (OFG), and left Temporal Occipital Fusiform Cortex (TOF)) that exhibited similar patterns on both SA and FA. Further analysis with virtual lesion techniques revealed that no single cluster was indispensable for predicting either FA or SA, suggesting a distributed neural network responsible for supporting both attention tasks. Additional voxel-level analysis comparing the neural signature patterns further corroborated the distributed nature of FA and SA. In sum, by utilizing a machinelearning-based multivariate analysis approach with a large sample size, our study provides comprehensive evidence regarding the shared and distinct neural mechanisms underlying FA and SA. This approach overcomes previous limitations and sheds new light on the intricate nature of attentional processes.},
  url="https://www.biorxiv.org/content/10.1101/2023.08.20.554014v1.abstract",
  code="https://github.com/Anmin-Yang/attsig"
}

@article{yang2023nlp,
  abbr={Preprint},
  title={Natural language processing of narrative writing for depression screening in adolescents},
  author={Li*, Tian and Yang*, Anmin and Zhang, Guiting and Tang, Xin and Zhou, Ke and Liu, Jia},
  journal={Psyaxiv},
  volume={},
  number={},
  pages={},
  year={2023},
  publisher={Psyaxiv},
  abstract={Depression has become increasingly common among adolescents worldwide and has severe negative impact on an individual's mental and social development. Early identification and diagnosis of depression during adolescence are crucial for improving the well-being of affected individuals. While natural language processing (NLP) has shown effectiveness in identifying depression in adults via social media, its application in predicting depression in adolescents remains challenging. This study aimed to develop a simple yet highly applicable method for predicting depression in adolescents within a school setting. We collected written compositions from 4,715 students aged 10 to 17, using their scores on the Children's Depression Inventory (CDI) to categorize them into high-risk and low-risk groups for depression. Then, we developed three types of computational models combining various feature extraction (theory-based vs. data-based) and classification techniques (classical machine learning algorithm vs. state-of-the-art deep neural networks), and compared their predictive performance in identifying individuals at risk. We found that all models exhibited promising performance in predicting depressive tendencies, with the recurrent neural network model outperforming the others. Our study demonstrates the feasibility of employing students’ written compositions to identify those at higher risk of depression, and providing a potential solution for early detection of depressive tendencies in adolescents.},
  url="https://psyarxiv.com/5f9nb/",
  code="https://github.com/Anmin-Yang/nlp_depression"
}

@article{zhang2023connectome,
  abbr={Cereb. Cortex},
  title={A connectome-based neuromarker of nonverbal number acuity and arithmetic skills},
  author={Zhang, Dai and Zhou, Liqin and Yang, Anmin and Li, Shanshan and Chang, Chunqi and Liu, Jia and Zhou, Ke},
  journal={Cerebral Cortex},
  volume={33},
  number={3},
  pages={881--894},
  year={2023},
  publisher={Oxford University Press},
  abstract={The approximate number system (ANS) is vital for survival and reproduction in animals and is crucial for constructing abstract mathematical abilities in humans. Most previous neuroimaging studies focused on identifying discrete brain regions responsible for the ANS and characterizing their functions in numerosity perception. However, a neuromarker to characterize an individual’s ANS acuity is lacking, especially one based on whole-brain functional connectivity (FC). Here, based on the resting-state functional magnetic resonance imaging (rs-fMRI) data obtained from a large sample, we identified a distributed brain network (i.e. a numerosity network) using a connectome-based predictive modeling (CPM) analysis. The summed FC strength within the numerosity network reliably predicted individual differences in ANS acuity regarding behavior, as measured using a nonsymbolic number-comparison task. Furthermore, in an independent dataset of the Human Connectome Project (HCP), we found that the summed FC strength within the numerosity network also specifically predicted individual differences in arithmetic skills, but not domain-general cognitive abilities. Therefore, our findings revealed that the identified numerosity network could serve as an applicable neuroimaging-based biomarker of nonverbal number acuity and arithmetic skills.},
  url="https://academic.oup.com/cercor/article/33/3/881/6543489",
}

@article{zhang2022attention,
  abbr={PBB},
  title={The Influence of Cue Validity on Social Attention and Exogenous Attention},
  author={Zhang, Guiting and Yang, Anmin and Sun, Jialun and Zhou, Liqin and Zhou, Ke},
  journal={Progress in Biochemistry and Biophysics},
  volume={49},
  number={3},
  pages={584-590},
  year={2022},
  publisher={},  
  abstract={Social cues such as eye gaze, head direction, and walking direction of biological motion are critical for human survival and social interaction. Since social and peripheral cues both have reflexive characteristics of attentional orientation, social attention is often regarded as one kind of exogenous attention. However, empirical evidence suggests that this explanation cannot fully account for all phenomena of social attention. Whether social attention and exogenous attention possess the same mechanism remains unclear. Here, we used a typical spatial cueing paradigm to systematically examine the effects of cue validity on social attention and exogenous attention, triggered by eye gaze and peripheral cues, respectively. The results showed that both kinds of attention were affected by cue validity. With the increase of cue validity, the attention effects of eye gaze and peripheral cues increased. When the cue validity was noninformative (0.5) or strongly predictive (0.8), there was no significant difference in the attentional effects between social attention and exogenous attention. More importantly, however, when the cue validity was 0.2 (i. e., counterpredictive), the attentional effects of both cues were significantly different. While the facilitation effects of the eye gaze cue were weakened, the attentional effects of the peripheral cue were reversed and showed an inhibition pattern, suggesting that gaze-triggered attention is more strongly reflexive than exogenous attention orienting. Our finding thus provides new evidence supporting the theoretical hypothesis that there exist significant differences between social attention and classical exogenous attention, at least in certain stages of their processing. Our study also offers a new method to distinguish social attention and exogenous attention through voluntary attentional control.},
  url="https://www.pibb.ac.cn/pibbcn/article/abstract/20220036?st=article_issue",
}

# 2022
@article{zhou2022emerged,
  abbr={Sci. Adv.},
  title={Emerged human-like facial expression representation in a deep convolutional neural network},
  author={Zhou, Liqin and Yang, Anmin and Meng, Ming and Zhou, Ke},
  journal={Science advances},
  volume={8},
  number={12},
  pages={eabj4383},
  year={2022},
  publisher={American Association for the Advancement of Science},
  abstract={Recent studies found that the deep convolutional neural networks (DCNNs) trained to recognize facial identities
spontaneously learned features that support facial expression recognition, and vice versa. Here, we showed that
the self-emerged expression-selective units in a VGG-Face trained for facial identification were tuned to distinct
basic expressions and, importantly, exhibited hallmarks of human expression recognition (i.e., facial expression
confusion and categorical perception). We then investigated whether the emergence of expression-selective units
is attributed to either face-specific experience or domain-general processing by conducting the same analysis on
a VGG-16 trained for object classification and an untrained VGG-Face without any visual experience, both having
the identical architecture with the pretrained VGG-Face. Although similar expression-selective units were found
in both DCNNs, they did not exhibit reliable human-like characteristics of facial expression perception. Together,
these findings revealed the necessity of domain-specific visual experience of face identity for the development
of facial expression perception, highlighting the contribution of nurture to form human-like facial expression perception.},
  url="https://www.science.org/doi/full/10.1126/sciadv.abj4383"
}

# 2019
@article{liu2019manually,
  abbr={Sci. Data},
  title={A manually denoised audio-visual movie watching fMRI dataset for the studyforrest project},
  author={Liu, Xingyu and Zhen, Zonglei and Yang, Anmin and Bai, Haohao and Liu, Jia},
  journal={Scientific Data},
  volume={6},
  number={1},
  pages={295},
  year={2019},
  publisher={Nature Publishing Group UK London},
  abstract={The data presented here are related to the studyforrest project that uses the movie ‘Forrest Gump’ to map brain functions in a real-life context using functional magnetic resonance imaging (fMRI). However, neural-related fMRI signals are often small and confounded by various noise sources (i.e., artifacts) that makes searching for the signals induced by specific cognitive processes significantly challenging. To make neural-related signals stand out from the noise, the audio-visual movie watching fMRI dataset from the project was denoised by a combination of spatial independent component analysis and manual identification of signals or noise. Here, both the denoised data and the labeled decomposed components are shared to facilitate further study. Compared with the original data, the denoised data showed a substantial improvement in the temporal signal-to-noise ratio and provided a higher sensitivity in subsequent analyses such as in an inter-subject correlation analysis.},
  url="https://www.nature.com/articles/s41597-019-0303-3"
}